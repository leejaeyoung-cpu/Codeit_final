"""
í•˜ì´ë¸Œë¦¬ë“œ ë°°ê²½ ìƒì„± ë§¤ë‹ˆì €
ë¡œì»¬ GPU ë˜ëŠ” Replicate API ìë™ ì„ íƒ
"""
import logging
import torch
from typing import Optional
from PIL import Image

logger = logging.getLogger(__name__)


class HybridGenerator:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ë°°ê²½ ìƒì„±ê¸°

    GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ ìë™ìœ¼ë¡œ ë¡œì»¬/API ì„ íƒ

    Example:
        >>> # ìë™ ëª¨ë“œ (GPU ì²´í¬)
        >>> generator = HybridGenerator()
        >>> 
        >>> # ê°•ì œ ë¡œì»¬ ëª¨ë“œ
        >>> generator = HybridGenerator(force_mode="local")
        >>> 
        >>> # ê°•ì œ Replicate ëª¨ë“œ
        >>> generator = HybridGenerator(force_mode="replicate")
        >>> 
        >>> # ë°°ê²½ ìƒì„±
        >>> result = generator.generate_background(
        ...     product_image=img,
        ...     prompt_text="white minimal background",
        ...     style="minimal"
        ... )
    """

    def __init__(
        self,
        force_mode: Optional[str] = None,
        replicate_api_token: Optional[str] = None
    ):
        """
        Args:
            force_mode: ê°•ì œ ëª¨ë“œ ("local", "replicate", None=ìë™)
            replicate_api_token: Replicate API í† í°
        """
        # ì†ì„± ì´ˆê¸°í™”
        self.force_mode = force_mode
        self.replicate_api_token = replicate_api_token
        self.generator = None
        self.mode = "unknown"
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # ìƒì„±ê¸° ì´ˆê¸°í™”
        self._initialize_generator()

    def _check_gpu_available(self) -> bool:
        """
        GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

        Returns:
            True: GPU ì‚¬ìš© ê°€ëŠ¥ (CUDA + 6GB ì´ìƒ)
            False: GPU ì—†ìŒ ë˜ëŠ” ë©”ëª¨ë¦¬ ë¶€ì¡±
        """
        # 1. CUDA ì‚¬ìš© ê°€ëŠ¥ ì²´í¬
        if not torch.cuda.is_available():
            logger.info("âš ï¸ CUDA not available")
            return False

        try:
            # 2. GPU ì´ ë©”ëª¨ë¦¬ í™•ì¸
            gpu_props = torch.cuda.get_device_properties(0)
            total_memory_gb = gpu_props.total_memory / (1024**3)

            logger.info(f"ğŸ® GPU detected: {gpu_props.name}")
            logger.info(f"ğŸ’¾ Total GPU memory: {total_memory_gb:.1f} GB")

            # 3. ìµœì†Œ ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ í™•ì¸ (6GB)
            min_required_gb = 6.0
            if total_memory_gb < min_required_gb:
                logger.warning(
                    f"âš ï¸ GPU memory too low: {total_memory_gb:.1f} GB < {min_required_gb} GB"
                )
                return False

            # 4. ì¶”ê°€ ì •ë³´ ë¡œê¹…
            allocated_memory_gb = torch.cuda.memory_allocated(0) / (1024**3)
            reserved_memory_gb = torch.cuda.memory_reserved(0) / (1024**3)

            logger.info(f"   Allocated: {allocated_memory_gb:.2f} GB")
            logger.info(f"   Reserved: {reserved_memory_gb:.2f} GB")
            logger.info(f"   Available: {total_memory_gb - reserved_memory_gb:.2f} GB")

            return True

        except Exception as e:
            logger.error(f"âŒ GPU check failed: {e}")
            return False

    def _use_local_generator(self):
        """ë¡œì»¬ SDXL ìƒì„±ê¸° ì´ˆê¸°í™”"""
        try:
            # CPU ëª¨ë“œ ì²´í¬
            if self.device == "cpu":
                raise RuntimeError(
                    "Local SDXL generator requires CUDA GPU. "
                    "CPU mode is not supported due to memory and performance constraints. "
                    "Use Replicate API instead (auto mode will select it automatically)."
                )

            # CUDA ì‚¬ìš© ê°€ëŠ¥ ì²´í¬
            if not torch.cuda.is_available():
                raise RuntimeError(
                    "CUDA is not available. Cannot initialize local generator."
                )

            logger.info("ğŸš€ Initializing local SDXL generator...")
            # Note: SDXLGenerator êµ¬í˜„ í•„ìš”
            # self.generator = SDXLGenerator(device=self.device)
            # self.generator.load_model()
            self.mode = "local"
            logger.info("âœ… Local generator initialized")
            logger.warning("âš ï¸ SDXLGenerator not implemented yet - placeholder")

        except Exception as e:
            logger.error(f"âŒ Failed to initialize local generator: {e}")
            raise

    def _use_replicate_generator(self):
        """Replicate API ìƒì„±ê¸° ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸŒ Initializing Replicate API generator...")

            # 1. API í† í° í™•ì¸
            if not self.replicate_api_token:
                raise ValueError(
                    "Replicate API token is required. "
                    "Set REPLICATE_API_TOKEN in environment or pass api_token parameter"
                )

            # 2. ReplicateBackgroundGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            from app.service.processing.generators.replicate_generator import ReplicateBackgroundGenerator
            self.generator = ReplicateBackgroundGenerator(api_token=self.replicate_api_token)

            # 3. mode ì„¤ì •
            self.mode = "replicate"

            logger.info("âœ… Replicate generator initialized")

        except Exception as e:
            logger.error(f"âŒ Failed to initialize Replicate generator: {e}")
            raise

    def _initialize_generator(self):
        """ìƒì„±ê¸° ì´ˆê¸°í™” (ìë™ ì„ íƒ)"""

        # Case 1: ê°•ì œ ëª¨ë“œê°€ ì„¤ì •ëœ ê²½ìš°
        if self.force_mode:
            if self.force_mode == "local":
                logger.info("ğŸ”’ Force mode: LOCAL")
                self._use_local_generator()

            elif self.force_mode == "replicate":
                logger.info("ğŸ”’ Force mode: REPLICATE")
                self._use_replicate_generator()

            else:
                # ì˜ëª»ëœ force_mode
                raise ValueError(
                    f"Invalid force_mode: '{self.force_mode}'. "
                    f"Must be 'local', 'replicate', or None"
                )
            return

        # Case 2: ìë™ ëª¨ë“œ (GPU ì²´í¬)
        logger.info("ğŸ¤– Auto mode: Checking GPU availability...")

        if self._check_gpu_available():
            # GPU ì‚¬ìš© ê°€ëŠ¥ â†’ ë¡œì»¬ ì‹œë„
            try:
                self._use_local_generator()

            except Exception as e:
                # ë¡œì»¬ ì‹¤íŒ¨ â†’ Replicate Fallback
                logger.warning(f"âš ï¸ Local generator failed: {e}")
                logger.info("ğŸ”„ Falling back to Replicate API...")

                try:
                    self._use_replicate_generator()

                except Exception as replicate_error:
                    # ë‘˜ ë‹¤ ì‹¤íŒ¨
                    logger.error("âŒ Both generators failed")
                    raise RuntimeError(
                        f"Failed to initialize any generator. "
                        f"Local error: {e}, Replicate error: {replicate_error}"
                    )
        else:
            # GPU ì—†ìŒ â†’ Replicate ì‚¬ìš©
            logger.info("ğŸŒ No GPU available, using Replicate API")
            self._use_replicate_generator()

    def generate_background(
        self, 
        product_image: Image.Image, 
        prompt_text: str, 
        **kwargs
    ) -> Image.Image:
        """
        ë°°ê²½ ìƒì„± (í†µí•© ì¸í„°í˜ì´ìŠ¤)

        Args:
            product_image: ì œí’ˆ ì´ë¯¸ì§€ (ë°°ê²½ ì œê±°ëœ ìƒíƒœ)
            prompt_text: ìƒì„± í”„ë¡¬í”„íŠ¸
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
                - aspect_ratio: "square", "portrait", "landscape"
                - style: "minimal", "emotional", "street", "instagram"
                - negative_prompt: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
                - num_inference_steps: ìƒì„± ìŠ¤í…
                - controlnet_conditioning_scale: ControlNet ê°•ë„
                - padding_percent: ì´ë¯¸ì§€ íŒ¨ë”© (0.0~1.0)
                - vertical_alignment: ìˆ˜ì§ ì •ë ¬ ("top", "center", "bottom")
                - use_ip_adapter: IP-Adapter ì‚¬ìš© (ë¡œì»¬ë§Œ ì§€ì›)

        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€

        Raises:
            RuntimeError: ìƒì„±ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìƒì„± ì‹¤íŒ¨
        """
        # 1. ìƒì„±ê¸° ì´ˆê¸°í™” í™•ì¸
        if self.generator is None:
            raise RuntimeError("Generator not initialized")

        logger.info(f"ğŸ¨ Generating background using {self.mode.upper()} mode")
        logger.info(f"   Prompt: {prompt_text}")
        logger.info(f"   Image size: {product_image.size}")

        # 2. IP-Adapter ê²½ê³  (Replicate ëª¨ë“œ)
        if self.mode == "replicate" and kwargs.get("use_ip_adapter"):
            logger.warning("âš ï¸ IP-Adapter not supported in Replicate mode (ignored)")

        try:
            # 3. ìƒì„± ì‹¤í–‰
            result = self.generator.generate_background(
                product_image=product_image,
                prompt_text=prompt_text,
                **kwargs
            )

            logger.info(f"âœ… Background generated successfully ({result.size})")
            return result

        except Exception as e:
            logger.error(f"âŒ Generation failed in {self.mode} mode: {e}")

            # 4. Fallback ì‹œë„ (ìë™ ëª¨ë“œì´ê³  ë¡œì»¬ ì‹¤íŒ¨ ì‹œ)
            if self.mode == "local" and not self.force_mode:
                logger.info("ğŸ”„ Attempting fallback to Replicate...")

                try:
                    # Replicateìœ¼ë¡œ ì „í™˜
                    self._use_replicate_generator()

                    # ì¬ì‹œë„
                    result = self.generator.generate_background(
                        product_image=product_image,
                        prompt_text=prompt_text,
                        **kwargs
                    )

                    logger.info(f"âœ… Background generated with fallback ({result.size})")
                    return result

                except Exception as fallback_error:
                    logger.error(f"âŒ Fallback also failed: {fallback_error}")
                    raise RuntimeError(
                        f"Generation failed in both modes. "
                        f"Local: {e}, Replicate: {fallback_error}"
                    )

            # Fallback ë¶ˆê°€ëŠ¥ ë˜ëŠ” ì´ë¯¸ Replicate ëª¨ë“œ
            raise RuntimeError(f"Generation failed: {e}")

    def get_mode(self) -> str:
        """
        í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë“œ ë°˜í™˜

        Returns:
            "local", "replicate", "unknown"
        """
        return self.mode

    def switch_mode(self, mode: str):
        """
        ìˆ˜ë™ìœ¼ë¡œ ëª¨ë“œ ì „í™˜

        Args:
            mode: "local" or "replicate"

        Raises:
            ValueError: ì˜ëª»ëœ mode ê°’
            RuntimeError: ëª¨ë“œ ì „í™˜ ì‹¤íŒ¨

        Example:
            >>> generator = HybridGenerator()
            >>> generator.get_mode()
            'local'
            >>> generator.switch_mode('replicate')
            >>> generator.get_mode()
            'replicate'
        """
        # 1. mode ìœ íš¨ì„± ê²€ì‚¬
        if mode not in ["local", "replicate"]:
            raise ValueError(
                f"Invalid mode: '{mode}'. Must be 'local' or 'replicate'"
            )

        # 2. ì´ë¯¸ í•´ë‹¹ ëª¨ë“œë©´ ìŠ¤í‚µ
        if self.mode == mode:
            logger.info(f"â„¹ï¸ Already using {mode.upper()} mode")
            return

        logger.info(f"ğŸ”„ Switching mode: {self.mode.upper()} â†’ {mode.upper()}")

        # 3. force_mode ì—…ë°ì´íŠ¸
        old_mode = self.mode
        self.force_mode = mode

        try:
            # 4. ìƒì„±ê¸° ì¬ì´ˆê¸°í™”
            if mode == "local":
                self._use_local_generator()
            else:
                self._use_replicate_generator()

            logger.info(f"âœ… Mode switched successfully")

        except Exception as e:
            logger.error(f"âŒ Failed to switch mode: {e}")

            # ì›ë˜ ëª¨ë“œë¡œ ë³µêµ¬ ì‹œë„
            logger.info(f"ğŸ”„ Reverting to {old_mode.upper()} mode")
            self.force_mode = old_mode
            self.mode = old_mode

            raise RuntimeError(f"Failed to switch to {mode} mode: {e}")
